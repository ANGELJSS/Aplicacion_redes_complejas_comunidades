{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFjVaDD7Nowb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dfcomentario = pd.read_csv('/content/Encuesta_Comunidades.csv' , sep=';')\n",
        "dfcomentario"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO\n",
        "# 1) Limpieza del texto\n",
        "from unicodedata import normalize\n",
        "import re\n",
        "# Define una funcion para limpiar el texto y devolverlo en minusculas\n",
        "def clean(text):\n",
        "# Remueve todos los caracteres especiales dejando solo los alfabeticos\n",
        "    text=re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", normalize( \"NFD\", text), 0, re.I    )\n",
        "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
        "    return text.lower()\n",
        "\n",
        "# Limpia el texto en la columna comentario\n",
        "dfcomentario['Comentario_Limpio'] = dfcomentario['Comentario'].apply(clean)\n",
        "dfcomentario.head()"
      ],
      "metadata": {
        "id": "SxTgmDTIRn4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2-4 Tokenizacion, POS tagging, eliminacion de Stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# POS tagger dictionary\n",
        "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
        "\n",
        "def token_stop_pos(text):\n",
        "    tags = pos_tag(word_tokenize(text))\n",
        "\n",
        "    newlist = []\n",
        "    for word, tag in tags:\n",
        "        if word.lower() not in set(stopwords.words('spanish')):\n",
        "          newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
        "\n",
        "    return newlist"
      ],
      "metadata": {
        "id": "aioqnDtJS-Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario['POS_tagged'] = dfcomentario['Comentario_Limpio'].apply(token_stop_pos)\n",
        "dfcomentario.head()"
      ],
      "metadata": {
        "id": "sxZo4j6PUUby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5) Obtención de las palabras raíz – Lematización\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(pos_data):\n",
        "  lemma_rew = \" \"\n",
        "  for word, pos in pos_data:\n",
        "    if not pos:\n",
        "      lemma = word\n",
        "      lemma_rew = lemma_rew + \" \" + lemma\n",
        "    else:\n",
        "      lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
        "      lemma_rew = lemma_rew + \" \" + lemma\n",
        "\n",
        "    return lemma_rew\n",
        "\n",
        "dfcomentario['Lemma'] = dfcomentario['POS_tagged'].apply(lemmatize)\n",
        "dfcomentario.head()"
      ],
      "metadata": {
        "id": "vFSl2r3iUfZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario[['Comentario_Limpio', 'Lemma']]"
      ],
      "metadata": {
        "id": "TmumMOrxUlmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysentimiento"
      ],
      "metadata": {
        "id": "JZCzJWxaaotQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pysentimiento import create_analyzer\n",
        "import transformers\n",
        "\n",
        "transformers.logging.set_verbosity(transformers.logging.ERROR)\n",
        "\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")"
      ],
      "metadata": {
        "id": "oB_gqctiZcqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_sentimiento_completo(comentario):\n",
        "  res = analyzer.predict(comentario)\n",
        "  return pd.Series({'sentiment': res.output, **res.probas})\n",
        "\n",
        "def obtener_sentimiento(comentario):\n",
        "  res = analyzer.predict(comentario)\n",
        "  return  res.output\n",
        "\n",
        "def obtener_polaridad(comentario):\n",
        "  res = analyzer.predict(comentario)\n",
        "  score = 0\n",
        "  pos = res.probas[\"POS\"]\n",
        "  neg = res.probas[\"NEG\"]\n",
        "  neu = res.probas[\"NEU\"]\n",
        "\n",
        "  if pos > neg and pos>neu:\n",
        "    score=pos\n",
        "  if neg > pos and neg>neu:\n",
        "    score=neg\n",
        "  if neu > pos and neu>neg:\n",
        "    score=neu\n",
        "\n",
        "  return  score\n"
      ],
      "metadata": {
        "id": "JV9oz1YwcXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario['Analisis'] = dfcomentario['Comentario_Limpio'].apply(obtener_sentimiento)\n",
        "dfcomentario['Polaridad'] = dfcomentario['Comentario_Limpio'].apply(obtener_polaridad)"
      ],
      "metadata": {
        "id": "wBnXiutJeIja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario"
      ],
      "metadata": {
        "id": "Cv8OngQ2hkv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO\n",
        "#Term Frequency - Inverse Document Frequency (TF-IDF) Vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features = 5000, ngram_range = (2, 2))\n",
        "X = tfidf.fit_transform(dfcomentario[\"Comentario_Limpio\"])\n",
        "X.shape"
      ],
      "metadata": {
        "id": "vpW_HcjOiF_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering\n",
        "#Encoding Sentiment variable\n",
        "#LabelEncoder codifica etiquetas asignándoles números\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "Encoder = LabelEncoder()\n",
        "dfcomentario[\"Analisis_Texto\"] = dfcomentario[\"Analisis\"]\n",
        "dfcomentario[\"Analisis\"] = Encoder.fit_transform(dfcomentario[\"Analisis\"])\n",
        "dfcomentario[\"Analisis\"].value_counts()"
      ],
      "metadata": {
        "id": "s8nkEffDl0nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dfcomentario['Analisis']\n",
        "y"
      ],
      "metadata": {
        "id": "gF7VHLMAl4UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Balance the imbalanced dataset\n",
        "from collections import Counter\n",
        "\n",
        "Counter(y)"
      ],
      "metadata": {
        "id": "92TlFH5gl7Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "Balancer = SMOTE(random_state = 42)\n",
        "X_final, y_final = Balancer.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "cXGrGK4gl9BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_final)"
      ],
      "metadata": {
        "id": "ko_EmJfKl-d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TO DO\n",
        "#Entrenar un modelo de clasificación adecuado sobre los datos procesados ​​para la clasificación de sentimientos\n",
        "\n",
        "#Separar los datos en entrenamiento y prueba\n",
        "#Model Selection\n",
        "#Split the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "l4OGTQcXl_rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MNB = MultinomialNB()\n",
        "MNB.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GK8HIvCRmCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos el score de exactitud del modelo\n",
        "\n",
        "from sklearn import metrics\n",
        "predicted = MNB.predict(X_test)\n",
        "\n",
        "accuracy_score = metrics.accuracy_score(predicted, y_test)\n",
        "print(\"Accuracuy Score: \",accuracy_score)"
      ],
      "metadata": {
        "id": "c5Z0v7zWmDbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "ConfusionMatrix = confusion_matrix(y_test, predicted )"
      ],
      "metadata": {
        "id": "TmOJVrdHmFM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Function for Confusion Matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "colors = ['#4F6272', '#B7C3F3', '#DD7596']\n",
        "\n",
        "def plot_cm(cm, classes, title, normalized = False, cmap = plt.cm.BuPu):\n",
        "    import numpy as np\n",
        "    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n",
        "    plt.title(title, pad = 20)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "    if normalized:\n",
        "        cm = cm.astype('float') / cm.sum(axis = 1)[: np.newaxis]\n",
        "        print(\"Matriz de Confusion Normalizada\")\n",
        "    else:\n",
        "        print(\"Matriz de Confusion No-Normalizada\")\n",
        "\n",
        "    threshold = cm.max() / 2\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i, j], horizontalalignment = \"center\", color = \"white\" if cm[i, j] > threshold else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.xlabel(\"Etiqueta predicha\", labelpad = 20)\n",
        "    plt.ylabel(\"Etiqueta real\", labelpad = 20)"
      ],
      "metadata": {
        "id": "CuR8lRpRmG6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cm(ConfusionMatrix, classes = [\"Positivo\", \"Neutral\", \"Negativo\"], title = \"Matriz de Confusion del Analisis de Sentimiento\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('matriz_confusion-png', dpi=300)"
      ],
      "metadata": {
        "id": "M9sCA_twmJC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "id": "GbfDGWZKmKcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model building\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "#lr = LogisticRegression()\n",
        "SVC = SVC()\n",
        "rf = RandomForestClassifier()\n",
        "Bayes = BernoulliNB()\n",
        "KNN = KNeighborsClassifier()\n",
        "\n",
        "#Models = [dt, lr, SVC, rf, Bayes, KNN]\n",
        "Models = [dt, SVC, rf, Bayes, KNN]\n",
        "#Models_Dict = {0: \"Decision Tree\", 1: \"Logistic Regression\", 2: \"SVC\", 3: \"Random Forest\", 4: \"Naive Bayes\", 5: \"K-Neighbors\"}\n",
        "\n",
        "Models_Dict = {0: \"Decision Tree\", 1: \"SVC\", 2: \"Random Forest\", 3: \"Naive Bayes\", 4: \"K-Neighbors\"}\n",
        "\n",
        "for i, model in enumerate(Models):\n",
        "  print(\"{} Test Accuracy: {}\".format(Models_Dict[i], cross_val_score(model, X, y, cv = 10, scoring = \"accuracy\").mean()))"
      ],
      "metadata": {
        "id": "Ud-mb_RqmMsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario.to_csv('dfcomentario.csv')"
      ],
      "metadata": {
        "id": "jTcY_mAcmYqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcomentario.head()"
      ],
      "metadata": {
        "id": "7A5kXE5Cnjvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_neg = dfcomentario[dfcomentario['Analisis_Texto'] == 'NEG']\n",
        "df1_neg = df1_neg.groupby(['Localidad']).agg(['count'])\n",
        "df1_neg['NombreCompleto']"
      ],
      "metadata": {
        "id": "iY5GfRSgRnNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_pos = dfcomentario[dfcomentario['Analisis_Texto'] == 'POS']\n",
        "df1_pos = df1_pos.groupby(['Localidad']).agg(['count'])\n",
        "df1_pos['NombreCompleto']"
      ],
      "metadata": {
        "id": "U-X336dASL9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_neu = dfcomentario[dfcomentario['Analisis_Texto'] == 'NEU']\n",
        "df1_neu = df1_neu.groupby(['Localidad']).agg(['count'])\n",
        "df1_neu['NombreCompleto']"
      ],
      "metadata": {
        "id": "HE0TFV1sSZbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}